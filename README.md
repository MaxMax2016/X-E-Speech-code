# X-E-Speech

## X-E-Speech: Joint Training Framework of Non-Autoregressive Cross-lingual Emotional Text-to-Speech and Voice Conversion


Demo page: https://X-E-Speech.github.io/X-E-Speech-demopage


Anonymous preprint: [https://openreview.net/forum?id=J4fL6FD](https://openreview.net/forum?id=J4fL6FDz36)

The generation of whisper encoder output refer to: https://github.com/PlayVoice/lora-svc
(I will upload the code and instruction for data process later)

The inference and train codes are available now, the environment is similar to VITS.

The pre-trained models are available here: https://drive.google.com/drive/folders/1PHzFyqkOa_7O4TVI6vypZa8MIpU7nIbT?usp=sharing

I will write a better readme and manage the code in the following days. (Actually, if you are very familiar with VITS, just read the code, you can understand what I changed on the VITS)


